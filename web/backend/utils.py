from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import torch
from web.backend.PINN_utils.PINN_class import DINN
import numpy as np
import pandas as pd
import streamlit as st
import os

def load_model(filepath, t, S_data, I_data, D_data, R_data):
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å"""
    print("–∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏")
    checkpoint = torch.load(filepath)

    # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä –º–æ–¥–µ–ª–∏
    model = DINN(t, S_data, I_data, D_data, R_data)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    model.load_state_dict(checkpoint['model_state_dict'])
    model.beta_tilda = checkpoint['beta_tilda']
    model.gamma_tilda = checkpoint['gamma_tilda']
    model.S_max = checkpoint['S_max']
    model.I_max = checkpoint['I_max']
    model.D_max = checkpoint['D_max']
    model.R_max = checkpoint['R_max']
    model.S_min = checkpoint['S_min']
    model.I_min = checkpoint['I_min']
    model.D_min = checkpoint['D_min']
    model.R_min = checkpoint['R_min']
    model.t = checkpoint['t']
    model.S = checkpoint['S']
    model.I = checkpoint['I']
    model.D = checkpoint['D']
    model.R = checkpoint['R']

    # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã
    model.t_float = model.t.float()
    model.t_batch = torch.reshape(model.t_float, (len(model.t), 1))
    model.S_hat = (model.S - model.S_min) / (model.S_max - model.S_min)
    model.I_hat = (model.I - model.I_min) / (model.I_max - model.I_min)
    model.D_hat = (model.D - model.D_min) / (model.D_max - model.D_min)
    model.R_hat = (model.R - model.R_min) / (model.R_max - model.R_min)

    print(f"Model loaded from {filepath}")
    return model


def calculate_metrics(y_true, y_pred):
    """
    Calculate regression metrics

    Parameters:
    y_true: array-like, true values
    y_pred: array-like, predicted values

    Returns:
    dict: Dictionary with MAE, MSE, RMSE, R2 metrics
    """
    # Convert to numpy arrays if they are tensors
    if torch.is_tensor(y_true):
        y_true = y_true.detach().numpy()
    if torch.is_tensor(y_pred):
        y_pred = y_pred.detach().numpy()

    # Ensure they are 1D arrays
    y_true = np.array(y_true).flatten()
    y_pred = np.array(y_pred).flatten()

    # Calculate metrics
    mae = mean_absolute_error(y_true, y_pred)
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_true, y_pred)

    metrics = {
        'MAE': mae,
        'MSE': mse,
        'RMSE': rmse,
        'R2': r2
    }

    return metrics


def compare_metrics(metrics_dict1, metrics_dict2, model1_name="–ú–æ–¥–µ–ª—å 1", model2_name="–ú–æ–¥–µ–ª—å 2"):
    """
    –°–æ–∑–¥–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—É –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫ –¥–≤—É—Ö –º–æ–¥–µ–ª–µ–π
    
    Parameters:
    metrics_dict1: dict, –º–µ—Ç—Ä–∏–∫–∏ –ø–µ—Ä–≤–æ–π –º–æ–¥–µ–ª–∏
    metrics_dict2: dict, –º–µ—Ç—Ä–∏–∫–∏ –≤—Ç–æ—Ä–æ–π –º–æ–¥–µ–ª–∏
    model1_name: str, –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–µ—Ä–≤–æ–π –º–æ–¥–µ–ª–∏
    model2_name: str, –Ω–∞–∑–≤–∞–Ω–∏–µ –≤—Ç–æ—Ä–æ–π –º–æ–¥–µ–ª–∏
    """

    # –°–æ–∑–¥–∞–µ–º DataFrame –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    comparison_df = pd.DataFrame({
        '–ú–µ—Ç—Ä–∏–∫–∞': list(metrics_dict1.keys()),
        model1_name: list(metrics_dict1.values()),
        model2_name: list(metrics_dict2.values())
    })

    # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–Ω–∏—Ü—É –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏
    comparison_df['–†–∞–∑–Ω–∏—Ü–∞'] = comparison_df[model1_name] - \
        comparison_df[model2_name]

    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —á–∏—Å–ª–∞ –¥–ª—è –ª—É—á—à–µ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
    for col in [model1_name, model2_name, '–†–∞–∑–Ω–∏—Ü–∞']:
        comparison_df[col] = comparison_df[col].apply(lambda x: f"{x:.4f}")

    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ç–∞–±–ª–∏—Ü—É
    st.header("üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –º–æ–¥–µ–ª–µ–π")
    st.dataframe(comparison_df, hide_index=True, width='stretch')

    return comparison_df


def download_temp_file(file_path, button_label="üì• –°–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª"):
    """
    –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    
    file_path: –ø—É—Ç—å –∫ –≤—Ä–µ–º–µ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
    button_label: —Ç–µ–∫—Å—Ç –Ω–∞ –∫–Ω–æ–ø–∫–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
    """
    if os.path.exists(file_path):
        with open(file_path, "rb") as file:
            file_data = file.read()

        file_name = os.path.basename(file_path)

        st.download_button(
            label=button_label+" "+file_name,
            data=file_data,
            file_name=file_name,
            mime="application/octet-stream",
            on_click="ignore"
        )
    else:
        st.error(f"–§–∞–π–ª {file_path} –Ω–µ –Ω–∞–π–¥–µ–Ω")

def get_data_for_model(filepath):
    x = 180 # —Å–∫–æ–ª—å–∫–æ –¥–Ω–µ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è

    covid_cases = pd.read_csv(filepath)
    susceptible = []
    infected = []
    dead = []
    recovered = []
    timesteps = []

    d1 = covid_cases['S']
    d2 = covid_cases['I']
    d3 = covid_cases['D']
    d4 = covid_cases['R']
    d5 = covid_cases['t']

    for item in range(len(d5)):
        if item % 1 == 0:
            susceptible.append(d1[item])
            infected.append(d2[item])
            dead.append(d3[item])
            recovered.append(d4[item])
            timesteps.append(d5[item])


    return timesteps, susceptible, infected, dead, recovered, x
